{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/gZQgOWPt5hg?si=X6WABd7jMlVfZwal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 0 으로 강제 설정\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#device = torch.device(\"cuda:\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기능.1 : 김형섭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "from datetime import datetime\n",
    "# from fastapi import HTTPException\n",
    "\n",
    "OUTPUT_FOLDER = \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(video_url: str):\n",
    "    \"\"\"유튜브 비디오에서 오디오 추출하여 output_folder에 저장\"\"\"\n",
    "\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)       # output_folder 생성\n",
    "\n",
    "    # 타임스탬프 추가 (파일명 중복 방지)\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    audio_filename = \"extracted_audio\"\n",
    "    audio_path = os.path.join(OUTPUT_FOLDER, audio_filename)\n",
    "\n",
    "    # 유튜브 오디오 다운로드 옵션 설정\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": audio_path,                      # 저장될 경로 지정\n",
    "        \"postprocessors\": [{\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\"\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])               # 유튜브에서 오디오 다운로드\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # raise HTTPException(status_code=500, detail=f\"오디오 추출 실패: {str(e)}\")\n",
    "\n",
    "    return audio_path                               # 다운로드된 파일 경로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/gZQgOWPt5hg?si=X6WABd7jMlVfZwal\n",
      "[youtube] gZQgOWPt5hg: Downloading webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] gZQgOWPt5hg: Downloading tv client config\n",
      "[youtube] gZQgOWPt5hg: Downloading player b191cf34\n",
      "[youtube] gZQgOWPt5hg: Downloading tv player API JSON\n",
      "[youtube] gZQgOWPt5hg: Downloading ios player API JSON\n",
      "[youtube] gZQgOWPt5hg: Downloading m3u8 information\n",
      "[info] gZQgOWPt5hg: Downloading 1 format(s): 251\n",
      "[download] Destination: /home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/extracted_audio\n",
      "[download] 100% of    4.36MiB in 00:00:00 at 45.36MiB/s    \n",
      "[ExtractAudio] Destination: /home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/extracted_audio.mp3\n",
      "Deleting original file /home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/extracted_audio (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_audio(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/extracted_audio'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기능.2 : 지서연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "def initialize_gpu():\n",
    "    \"\"\"\n",
    "    GPU 캐시, IPC, 가비지 컬렉션 실행 후 GPU 동기화 및 초기화\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    # os.system(\"nvidia-smi --gpu-reset\")  # 필요시 주석 해제 (관리자 권한 필요)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def load_asr_pipeline(model_id: str, torch_dtype,  device: str):\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch_dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    asr_pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype, #torch.float16,\n",
    "        device=device,\n",
    "    )\n",
    "    return asr_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline at 0x7f5dd6d59570>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 \n",
    "\n",
    "model_id = \"openai/whisper-large\"\n",
    "\n",
    "load_asr_pipeline(model_id, torch_dtype, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def remove_extra_repeated_words(text: str) -> str:\n",
    "    \"\"\"\n",
    "    동일한 한글 단어가 3번 이상 반복될 경우 2개만 남기고 나머지 삭제\n",
    "    (숫자 및 특수문자는 유지)\n",
    "    \"\"\"\n",
    "    word_count = defaultdict(int)\n",
    "    word_positions = {}\n",
    "    \n",
    "    for match in re.finditer(r\"[가-힣]+\", text):\n",
    "        word = match.group()\n",
    "        word_count[word] += 1\n",
    "        word_positions.setdefault(word, []).append(match.start())\n",
    "    \n",
    "    result = list(text)\n",
    "    for word, positions in word_positions.items():\n",
    "        if word_count[word] > 2:\n",
    "            for i in range(2, len(positions)):\n",
    "                start_idx = positions[i]\n",
    "                for j in range(len(word)):\n",
    "                    result[start_idx + j] = \"\"\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "# from gpu_utils import initialize_gpu\n",
    "# from asr_model import load_asr_pipeline\n",
    "# from text_utils import remove_extra_repeated_words\n",
    "\n",
    "def main():\n",
    "    # GPU 초기화\n",
    "    initialize_gpu()\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 \n",
    "\n",
    "    model_id = \"openai/whisper-small\"\n",
    "    asr_pipe = load_asr_pipeline(model_id, torch_dtype, device)\n",
    "\n",
    "    # 음성 인식 설정 (forced_decoder_ids를 생략하여 내부 language 옵션 사용)\n",
    "    generate_kwargs = {\n",
    "        \"max_new_tokens\": 445,\n",
    "        \"num_beams\": 1,\n",
    "        \"condition_on_prev_tokens\": False,\n",
    "        \"compression_ratio_threshold\": 1.35,\n",
    "        \"temperature\": (0.0, 0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "        \"logprob_threshold\": -1.0,\n",
    "        \"no_speech_threshold\": 0.6,\n",
    "        \"return_timestamps\": True,\n",
    "        # language 옵션은 내부적으로 처리하도록 합니다.\n",
    "    }\n",
    "    \n",
    "    # 오디오 파일 경로\n",
    "    audio_path = r'/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/extracted_audio.mp3'\n",
    "    # language 옵션을 generate_kwargs에 포함하지 않고, 파이프라인 내부에서 설정하게 함.\n",
    "    result = asr_pipe(audio_path, generate_kwargs={\"language\": \"korean\"}, return_timestamps=True)\n",
    "    \n",
    "    test_text = result.get(\"text\", \"\")\n",
    "    cleaned_text = remove_extra_repeated_words(test_text)\n",
    "    print(\"처리된 텍스트:\", cleaned_text)\n",
    "    \n",
    "    output_file = \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/processed_text.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text)\n",
    "    print(f\"최종 텍스트가 '{output_file}'에 저장되었습니다.\")\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/wanted-1/miniconda3/envs/whisper/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed language=korean, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=korean.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 텍스트:  요즘 은행 대출 전구 가보신 분들은 대출 밖에 얼마나 힘든지 세삼 느끼실 겁니다. 하반기에는 더 어려워질 거라는데 왜 그런 건지 어떻게 하면  잘 받을 수 있을지 상담 받아보겠습니다. 레오대출 연구소 김은진 대표와 함께하겠습니다. 대표님 어서 오세요. 안녕하세요. 요즘은  받으려면 계절 잘 타야 된다고요. 이제 강을 이후 되면  창고가 다쳐버려서 올해도 그럴까요. 네 맞습니다. 이제 거의 공식화 된 것 같습니다. 그래서 올해도 역시 하반기에는 대출의 문턱이 더 높아질 것으로 보이고 있습니다. 여러 가지가 바뀔 예정이긴 한데요. 특히 눈에 띄는 것이 전세대출입니다. 그동안 전세대출은 규제가 조금 되지 않았던 부분이긴 한데 전세대출의 보증기관이 저기 보시는 대로 주택금융공사, 주택 보시 보증공사, 서울 보증 이렇게 세 군대가 있는데요. 여기서 보증해주면 은행이 대출을 해준다. 가운데 항상 등판을 해야 하는 세 곳의 기관인데  그 보증 비율을 축소하겠다고 발표를 했습니다.  비율을 100%에서 90%로 줄인다? 이러면  받는 데 어떤 영향이 있는지?   100%라고 하면 은행에서는 그냥 100% 다 받을 수 있기 때문에 전혀 손해가 없죠. 그런데 90%만, 혹시 부실이 나면 90%만 물어주겠다 이런 의미이기 때문에 은행 입장에서는 리스크가 발생합니다. 10%의 돈이 받지 못할 수도 있기  그래서 은행에서는 심사를 조금  강화할 수밖에 없는 상황이고요. 그리고 리스크가 있으니까 혹시  금리에도 영향을 미칠 수가 있는 그런 상황이 될  있습니다. 그러다 보면 저희가 서민들이 많이 거주하는 곳이 빌라라든지 다세대 열림 이런 곳이 많은데  부분에서도 역시 대출이 어려 워낙 할  있고요. 그러다 보면 서민들이 점점 월세로 가야 할 수도 있는 상황이 발생할  . 7월부터는 3단계 스트레스 DSR, 이거 도입된다면서요? 네, 뭐예요? 스트레스 DSR, 항상  이슈가 되는  단어인데요.  DSR이라는 것은 소득 대비,  한도가 정해지는  규정이라고 보시면 되는데  DSR 같은 경우는  금리가 높을수록,  만기가 짧을수록 분리해지는  상황인데 정부에서 우리 7월부터 3단계가 도입이 되면 좀  강화를 하게 됩니다. 그러면 당신의 대출가플 능력 보고 대출해줄 거잖아요. 그게  까다로워진다는 거죠. 그렇게  아무래도 가게 부치는 줄어들  있겠지만 내지 마련하시는 분들 입장에서는 어려움이 발생할  . 적용 범위나 금리 수준은 어떻게 되는데요. 올해 5월 전으로 해서 발표가 될 것 같고요. 그리고 원래 7월부터 시행하겠다고 예고를 되어 . 그런데 기준 금리가 점점 낮아지는 추세고 대출금이 낮아지면 그 디에살이   까다로워진다고 해도  한 대 큰 변화 없지 않을까? 그럴  . 왜냐하면 현재 기준 금리도  떨어지고  상황인데 이  디에살은 금리를  올리고  상황이라서 어찌  상세를  수가 있는데 지금 현재 시중 은행의 금리는 4% 초반에서 4% 중후반으로 형성이 되어 있는데. 4% 후반에서 5% 초반? 거기까지 형성이  있는데요. 우리 은행이 선주로 0.25% 정경 인하를 했고요. 앞으로 다른 은행들도 내 주에 점점점점  인하할 것으로 보입니다. 이렇게  인화되는 시기가  또  고민하잖아요. 가라탈까 하는 거. 어떤 거 좀 주의하면 돼요? 가라타게  때? 가라타게  때  본인의 금리하고 당연히 가라탈 금리를 비교를 해보는 게 우선이고요.  그다음에 한도를 걱정을 하셔야 됩니다. 왜냐하면 예전보다  높아졌기  가라탈  한도가 줄어들  있어요.   DS에 도입된다      있잖아요. 들  . 그렇게  내가  너무   같다  생각이 든다고   dsr 3단계가 적용되기 전에 대출을 대환하는 것을 고민해 보시는 것이  좋을  . 대표님  하시는 말씀이  받는데도 순서가 있다면서요. , 맞습니다. 뭐부터 받는 게 좋아요? 일단 상품으로 본다고  정책자금  먼저 받고 거기에 해당이 안 되시는 분들은  상품을   제일 좋습니다. 정책자금 대출이라면 버티목   . 보금자리로 대출이라든지  대출이 제일 좋은데요. 특히 신세가 특례  같은 경우에는  굉장히 저렴하거든요.  해당되시는  꼭 받으시는   좋고요. 아무래도 제한  많은 대출일수록 혜택이 많다고 보시면   같습니다. DSR을 따지는   마지막에 바라, 라는 말씀이신 거죠? 그것도 해당이 . 일단 정책상품 먼저   가장 좋고 혹시라도 내가 신용대출이라든지 기타  굉장히 많은 분들이 있어요.  분들  경우는 시용대출을  받으시고, 시용대출은 DSR을 보기  까다롭게  체크가 .  그걸  받고,    말씀하신 보금자리론이라든지 디딥돌   안 보거든요.    DSR  보다. . 보는  훨씬  유리할  . 알겠습니다. 대출도 아는  힘이다. 대출력.  키워볼게요. 김은진 대표와 함께 했습니다. 고맙습니다.\n",
      "최종 텍스트가 '/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/processed_text.txt'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_prompt = \"\"\"\n",
    "After reading the original text below, please perform the following steps in order:\n",
    "\n",
    "1. Translate the original text into English.\n",
    "2. Summarize the translated text by extracting only the most important core points. Present each key point as a numbered item. Each numbered item must:\n",
    "   - Begin with the item number followed by a period and a space (e.g., \"1. \").\n",
    "   - Contain only the key point in a simple and direct sentence.\n",
    "   - End with a period.\n",
    "3. Finally, translate the numbered summary into Korean.\n",
    "\n",
    "Important:\n",
    "- The final output must be only the summary in Korean.\n",
    "- The final summary must strictly follow the format below, with one key point per line:\n",
    "\n",
    "   1. [First key point in Korean].\n",
    "   2. [Second key point in Korean].\n",
    "   3. [Third key point in Korean].\n",
    "   (and so on...)\n",
    "\n",
    "- Do not include any extra commentary, notes, bullet symbols (such as \"*\" or \"-\"), or any text like \"Note:\".\n",
    "- Avoid repetition or duplication of words.\n",
    "- Use simple and direct language.\n",
    "\n",
    "Original Text:\n",
    "{original_text}\n",
    "\n",
    "Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 \n",
    "detailed_prompt = \"\"\"\n",
    "After reading the original text below, please perform the following steps in order:\n",
    "\n",
    "1. Translate the original text into English.\n",
    "2. Summarize the translated text by extracting only the most important core points. Present each key point as a numbered item (for example, \"1.\", \"2.\", \"3.\", etc.). Write each point concisely and clearly.\n",
    "3. Finally, translate the numbered summary into Korean.\n",
    "\n",
    "Important:\n",
    "- The final output must be only the summary in Korean.\n",
    "- Use simple and direct language.\n",
    "- Do not include any extra commentary, notes, or repeated information.\n",
    "- Each numbered point must be on a separate line and end with a period.\n",
    "- Do not include any bullet symbols (such as \"*\" or \"-\").\n",
    "- Do not write '**Note:**'\n",
    "- Do not include any notes, disclaimers, or additional comments. Only output the summary.\n",
    "- Do not write any 'Note:'\n",
    "- Avoid duplication of word\n",
    "\n",
    "Original Text:\n",
    "{original_text}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Only: 김은진과 동료들의 의견을 종합하여 볼 때, 만약 현행 장애물 및 재산권을 이용하지 않는 사람들에게 과도하게 경제적 불평등이 생길 가능성이 존재한다는 사실은 이미 증명되어 있으며 따라서, 위 법률에 근거해서 실제적으로 감액시킬 필요가 있다. 또한, 이러한 문제는 사회 전체적인 환경이나 개인의 취지를 고려해야하기 때문에 각자가 자신의 권리와 책임을 충족하려고 노력할 것이다. 따라서, 김은진에게 주어진 업무의 목적을 달성함 위한 직업을 선택할 자격은 없다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "# GPU 0 으로 강제 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 불러오기 \n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": torch.cuda.current_device()}\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/Gemma/path/to/save/lora_adapters_ver1_law\")\n",
    "model.eval()  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 하이퍼파라미터 조정\n",
    "generation_kwargs = {\n",
    "    \"max_length\": 5000,           # 최대 생성 토큰 수 (요약 길이 제한)\n",
    "    \"min_length\": 512,            # 최소 생성 토큰 수\n",
    "    \"do_sample\": True,           # 샘플링 방식 사용\n",
    "    \"temperature\": 0.3,          # 낮은 값은 결정론적, 높은 값은 다양성 증가\n",
    "    \"top_k\": 50,                 # 상위 k개 단어 내에서 샘플링\n",
    "    \"top_p\": 0.95,               # 누적 확률 p 내 단어에서 샘플\n",
    "    \"repetition_penalty\" : 1.9,\n",
    "}\n",
    "\n",
    "# 텍스트 파일 경로 수정\n",
    "txt_file_path = \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/processed_text.txt\"  # 파일 경로를 수정하세요.\n",
    "with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_text = f.read()\n",
    "\n",
    "\n",
    "# 프롬프트 \n",
    "detailed_prompt = \"\"\"\n",
    "Write the summary in complete sentences, ensuring that each sentence ends with a period.\n",
    "The summary must be composed of at least 3 sentences and no more than 5 sentences.\n",
    "Avoid unnecessary elaboration or repetition; be concise and clear.\n",
    "Accurately reflect the core information of the original text.\n",
    "\n",
    "### Original Text:\n",
    "{original_text}\n",
    "\n",
    "### Summary:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 구성\n",
    "prompt = detailed_prompt.format(original_text=original_text)\n",
    "\n",
    "#  요약 생성\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output_tokens = model.generate(**inputs, **generation_kwargs)\n",
    "\n",
    "# 후처리 \n",
    "def post_process(text):\n",
    "    # 앞뒤 공백 제거\n",
    "    text = text.strip()\n",
    "    # 불필요한 공백, 줄바꿈, 중복 문장 부호 제거 (예시: 느낌표, 공백 등)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'!{2,}', '!', text)\n",
    "    return text\n",
    "\n",
    "generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "# 4. \"Summary:\" 이후의 텍스트만 추출하여 순수 요약문만 저장\n",
    "if \"Summary:\" in generated_text:\n",
    "    summary_only = generated_text.split(\"Summary:\")[-1].strip()\n",
    "else:\n",
    "    summary_only = generated_text.strip()\n",
    "\n",
    "# \"Note:\"가 있다면, 그 뒤의 모든 텍스트를 제거\n",
    "if \"Note:\" in summary_only:\n",
    "    summary_only = summary_only.split(\"Note:\")[0].strip()\n",
    "\n",
    "\n",
    "# .txt 파일로 저장 \n",
    "with open(\"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/평가/generated_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_only)\n",
    "\n",
    "print(\"Summary Only:\", summary_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (PPL): 7.83115305459753\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def compute_perplexity(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에 대한 Perplexity(PPL)를 계산하는 함수.\n",
    "    텍스트를 토크나이즈한 후, 모델의 loss를 계산하고, 이를 기반으로 perplexity를 구함.\n",
    "    \"\"\"\n",
    "    # 텍스트 토크나이즈 및 텐서 변환\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = encodings.input_ids.to(model.device)\n",
    "    \n",
    "    # 모델 출력 (라벨에 input_ids를 넣어 self-supervised loss 계산)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    # Perplexity 계산 (exp(loss))\n",
    "    ppl = math.exp(loss.item())\n",
    "    return ppl\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 평가에 사용할 모델과 토크나이저 (예시로 GPT-2 사용)\n",
    "    model_name = \"gpt2\"  # 필요한 모델 이름으로 변경하세요.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # ---- Perplexity 평가 ----\n",
    "    # 평가할 텍스트 (예시)\n",
    "    text_input = \"김은진과 동료들의 의견을 종합하여 볼 때, 만약 현행 장애물 및 재산권을 이용하지 않는 사람들에게 과도하게 경제적 불평등이 생길 가능성이 존재한다는 사실은 이미 증명되어 있으며 따라서, 위 법률에 근거해서 실제적으로 감액시킬 필요가 있다. 또한, 이러한 문제는 사회 전체적인 환경이나 개인의 취지를 고려해야하기 때문에 각자가 자신의 권리와 책임을 충족하려고 노력할 것이다. 따라서, 김은진에게 주어진 업무의 목적을 달성함 위한 직업을 선택할 자격은 없다\"\n",
    "    ppl = compute_perplexity(text_input, model, tokenizer)\n",
    "    print(\"Perplexity (PPL):\", ppl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
