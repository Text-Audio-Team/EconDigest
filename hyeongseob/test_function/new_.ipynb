{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/ZOJCatQ9fQU?si=smLS1mZeZnwkVTM0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기능.1 : 김형섭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "from datetime import datetime\n",
    "# from fastapi import HTTPException\n",
    "\n",
    "OUTPUT_FOLDER = \"/home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(video_url: str):\n",
    "    \"\"\"유튜브 비디오에서 오디오 추출하여 output_folder에 저장\"\"\"\n",
    "\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)       # output_folder 생성\n",
    "\n",
    "    # 타임스탬프 추가 (파일명 중복 방지)\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    audio_filename = \"extracted_audio\"\n",
    "    audio_path = os.path.join(OUTPUT_FOLDER, audio_filename)\n",
    "\n",
    "    # 유튜브 오디오 다운로드 옵션 설정\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": audio_path,                      # 저장될 경로 지정\n",
    "        \"postprocessors\": [{\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\"\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])               # 유튜브에서 오디오 다운로드\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # raise HTTPException(status_code=500, detail=f\"오디오 추출 실패: {str(e)}\")\n",
    "\n",
    "    return audio_path                               # 다운로드된 파일 경로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/ZOJCatQ9fQU?si=smLS1mZeZnwkVTM0\n",
      "[youtube] ZOJCatQ9fQU: Downloading webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] ZOJCatQ9fQU: Downloading tv client config\n",
      "[youtube] ZOJCatQ9fQU: Downloading player 5ae7d525\n",
      "[youtube] ZOJCatQ9fQU: Downloading tv player API JSON\n",
      "[youtube] ZOJCatQ9fQU: Downloading ios player API JSON\n",
      "[youtube] ZOJCatQ9fQU: Downloading m3u8 information\n",
      "[info] ZOJCatQ9fQU: Downloading 1 format(s): 251\n",
      "[download] Destination: /home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder/extracted_audio\n",
      "[download] 100% of    3.82MiB in 00:00:00 at 21.19MiB/s    \n",
      "[ExtractAudio] Destination: /home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder/extracted_audio.mp3\n",
      "Deleting original file /home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder/extracted_audio (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_audio(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder/extracted_audio'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기능.2 : 지서연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanted-1/miniconda3/envs/whisper/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "def load_asr_pipeline(model_id: str, torch_dtype,  device: str):\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch_dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    asr_pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype, #torch.float16,\n",
    "        device=device,\n",
    "    )\n",
    "    return asr_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline at 0x7f7764433790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 \n",
    "\n",
    "model_id = \"openai/whisper-small\"\n",
    "\n",
    "load_asr_pipeline(model_id, torch_dtype, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def remove_extra_repeated_words(text: str) -> str:\n",
    "    \"\"\"\n",
    "    동일한 한글 단어가 3번 이상 반복될 경우 2개만 남기고 나머지 삭제\n",
    "    (숫자 및 특수문자는 유지)\n",
    "    \"\"\"\n",
    "    word_count = defaultdict(int)\n",
    "    word_positions = {}\n",
    "    \n",
    "    for match in re.finditer(r\"[가-힣]+\", text):\n",
    "        word = match.group()\n",
    "        word_count[word] += 1\n",
    "        word_positions.setdefault(word, []).append(match.start())\n",
    "    \n",
    "    result = list(text)\n",
    "    for word, positions in word_positions.items():\n",
    "        if word_count[word] > 2:\n",
    "            for i in range(2, len(positions)):\n",
    "                start_idx = positions[i]\n",
    "                for j in range(len(word)):\n",
    "                    result[start_idx + j] = \"\"\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "def initialize_gpu():\n",
    "    \"\"\"\n",
    "    GPU 캐시, IPC, 가비지 컬렉션 실행 후 GPU 동기화 및 초기화\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    # os.system(\"nvidia-smi --gpu-reset\")  # 필요시 주석 해제 (관리자 권한 필요)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "# from gpu_utils import initialize_gpu\n",
    "# from asr_model import load_asr_pipeline\n",
    "# from text_utils import remove_extra_repeated_words\n",
    "\n",
    "def main():\n",
    "    # GPU 초기화\n",
    "    initialize_gpu()\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 \n",
    "\n",
    "    model_id = \"openai/whisper-small\"\n",
    "    asr_pipe = load_asr_pipeline(model_id, torch_dtype, device)\n",
    "\n",
    "    # 음성 인식 설정 (forced_decoder_ids를 생략하여 내부 language 옵션 사용)\n",
    "    generate_kwargs = {\n",
    "        \"max_new_tokens\": 445,\n",
    "        \"num_beams\": 1,\n",
    "        \"condition_on_prev_tokens\": False,\n",
    "        \"compression_ratio_threshold\": 1.35,\n",
    "        \"temperature\": (0.0, 0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "        \"logprob_threshold\": -1.0,\n",
    "        \"no_speech_threshold\": 0.6,\n",
    "        \"return_timestamps\": True,\n",
    "        # language 옵션은 내부적으로 처리하도록 합니다.\n",
    "    }\n",
    "    \n",
    "    # 오디오 파일 경로\n",
    "    audio_path = r'/home/wanted-1/potenup-workspace/Project/project3/team2/02_WebFramework/output_folder/extracted_audio.mp3'\n",
    "    # language 옵션을 generate_kwargs에 포함하지 않고, 파이프라인 내부에서 설정하게 함.\n",
    "    result = asr_pipe(audio_path, generate_kwargs={\"language\": \"korean\"}, return_timestamps=True)\n",
    "    \n",
    "    test_text = result.get(\"text\", \"\")\n",
    "    cleaned_text = remove_extra_repeated_words(test_text)\n",
    "    print(\"처리된 텍스트:\", cleaned_text)\n",
    "    \n",
    "    output_file = \"processed_text.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text)\n",
    "    print(f\"최종 텍스트가 '{output_file}'에 저장되었습니다.\")\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/wanted-1/miniconda3/envs/whisper/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed language=korean, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=korean.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 텍스트:  지난해 8월 어렵살이 미국 영주권을 취득했던 애틀렌타 한인 A 씨는 지난 6일 조지아주 연방 이민법원에서 열린 추방 재판에서 한국추방 판결을 받았습니다. 영주권 취득 6개월 만에 마주한 청천병력 같은 현실이었습니다. 이민 초기, 범죄에 휘말려 기소됐지만 단순 가담으로 정상이 참작돼 시령을 피했던 a 씨는 영주권 신청 과정에서도 이를 해명하기 위해 동분서주했습니다. 여러 차례의 서류 보완을 통해 해명 을 들은 연반 이민국은 미국 정착 에 문제가 없다며 그린 카드를 최종 발급해줬습니다. 꿈에 그리던 영주권을 받은 a 씨 는 두 달 후인 지난해 10월 한국에 있는 가족을 방문하기 위해 출국 했습니다. 그동안 신분 해결이 안되 비행기를 탈 수 없었기 때문에 10여 년 만에 밟은 모국당이었습니다. 하지만 2개월간의 한국체류를 마치고 12 중순 애틀렌타 국제공항을 통해 귀국하던 ac를 기다린 것은 생각지도 못했던 악몽이었습니다. 입국심사를 담당한 연방세관 국경보호국 cbp심사관은 ac의 영주권에 있는 외국인 등록번호를 확인하더니 2차 심사실로 끌고 갔습니다. 심사실에서 이전 범죄기록을 추금 받은 a   신청 과정에서 문제를 해결했고 이민국도 이를 받아들였다고 설명했지만 cbp 유원들은 a 씨에게 수갑을 채워 곧바로 조지아주 스튜어트 이민국 치소에 수감시켰습니다. a 씨에 대한 추방 재판은 이례적으로 신속하게 진행됐고 체포 두 달도 안 돼  판결이 내려졌습니다. a 씨를 면역했던  총영사관 관계자는 지난달 28일 한인 첫 불체자 케이스로 체포된 이면우 씨도 보름만 인 지난 14 추반 판결이 내려졌 다면서 이 구치소에 수감됐다가 이달 초 한국으로 송환된 다른 한 인도 영주권자였다고 말했습니다. 총영사관 관계자는 영주권자 등 합법 체류자라 할지라도 과거의 범죄 이력이 있으면 지금은 한국 등의 해외여행을 자제하는 것이 좋 다면서 합법체류 판정당국인 연방 이민국이 승인한  등의 합법 신분을 부여하더라도 단속당국인 cbp나  이민세관 단속국 icg 가  인정하지 않는 경우도 있어 유의해야 한다고 당부했습니다. 일단 추방대상이 되는 중범죄나 비교적 최근에 기록된 범죄 이력 이 해외여행에 가장 위험한 것으로 보이지만 어떠한 범죄도 안전할 수 없다는 분석도 나오고 있습니다. 실제 지난달 엘라베 마주에 거주하는 한인지상사 직원 bc는 음주운전 단속 속에 적발된 후 며칠  이민국 으로부터 비자 취소 통지서를 받기도 했습니다. 또한  스튜어트 이민구 취소에 수감된 한 스페인 여성의 경우  시민권자와의 결혼 으로  취득했지만  1980년대 저질은  기록이 드러나  재판에 넘겨진 것으로 알려졌습니다. 다른 나라 출신들에 비해 상대적으로  국경을 넘어온 미립국자가 적은 한인들의 경우 앞으로도 영주권자 등  체류자가 오히려 불체자 이민 단속 에 표적이 될 것이라는 전망 도 있습니다. 도널드 트럼프 대통령은 최근   실적이 저조하다며 분노를 표하기도 했는데 당국은 실적을 올리기 위해서라도 미국에서 오래 생활하며 각종 공공기록을 남긴  체류자를 먼저 단속할 확률이 높기 때문입니다. 한편 최근  판결을  한인들은 모두 추방에 앞서 재산과 신변 정리를 위한 가석방을  법원  요청했지만 전부 기각됐습니다. 트럼프 정부의  법원들이  판사 부족 사태 속에서도  당국의 보조를 맞추기  가능한 신속한 재판과 추방을 추진하고 있기 때문입니다. 이에 따라 해당 한인들은 아무런 정리도 하지 못한 채 한국 정부 가 발급한 여행 허가서를 발급 받는 대로 본국으로 추방될 예정입니다.\n",
      "최종 텍스트가 'processed_text.txt'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "# GPU 0 으로 강제 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 불러오기 \n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": torch.cuda.current_device()}\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/Gemma/path/to/save/lora_adapters_ver1_law\")\n",
    "model.eval()  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 하이퍼파라미터 조정\n",
    "generation_kwargs = {\n",
    "    \"max_length\": 4096,           # 최대 생성 토큰 수 (요약 길이 제한)\n",
    "    \"min_length\": 512,            # 최소 생성 토큰 수\n",
    "    \"do_sample\": True,           # 샘플링 방식 사용\n",
    "    \"temperature\": 0.5,          # 낮은 값은 결정론적, 높은 값은 다양성 증가\n",
    "    \"top_k\": 50,                 # 상위 k개 단어 내에서 샘플링\n",
    "    \"top_p\": 0.95,               # 누적 확률 p 내 단어에서 샘플\n",
    "}\n",
    "\n",
    "# 텍스트 파일 경로 수정\n",
    "txt_file_path = \"/home/wanted-1/potenup-workspace/Project/project3/team2/SY/Gemma/processed_text.txt\"  # 파일 경로를 수정하세요.\n",
    "with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_text = f.read()\n",
    "\n",
    "# 프롬프트 \n",
    "detailed_prompt = \"\"\"\n",
    "After reading the original text below, please perform the following steps in order:\n",
    "\n",
    "1. Translate the original text into English.\n",
    "2. Summarize the translated text by extracting only the most important core points. Present each key point as a numbered item (for example, \"1.\", \"2.\", \"3.\", etc.). Write each point concisely and clearly.\n",
    "3. Finally, translate the numbered summary into Korean.\n",
    "\n",
    "Important:\n",
    "- The final output must be only the summary in Korean.\n",
    "- Use simple and direct language.\n",
    "- Do not include any extra commentary, notes, or repeated information.\n",
    "- Each numbered point must be on a separate line and end with a period.\n",
    "- Do not include any bullet symbols (such as \"*\" or \"-\").\n",
    "- Do not write '**Note:**'\n",
    "- Do not include any notes, disclaimers, or additional comments. Only output the summary.\n",
    "- Do not write any 'Note:'\n",
    "- Avoid duplication of word\n",
    "\n",
    "Original Text:\n",
    "{original_text}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 구성\n",
    "prompt = detailed_prompt.format(original_text=original_text)\n",
    "\n",
    "#  요약 생성\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output_tokens = model.generate(**inputs, **generation_kwargs)\n",
    "\n",
    "# 후처리 \n",
    "def post_process(text):\n",
    "    # 앞뒤 공백 제거\n",
    "    text = text.strip()\n",
    "    # 불필요한 공백, 줄바꿈, 중복 문장 부호 제거 (예시: 느낌표, 공백 등)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'!{2,}', '!', text)\n",
    "    return text\n",
    "\n",
    "generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "# 4. \"Summary:\" 이후의 텍스트만 추출하여 순수 요약문만 저장\n",
    "if \"Summary:\" in generated_text:\n",
    "    summary_only = generated_text.split(\"Summary:\")[-1].strip()\n",
    "else:\n",
    "    summary_only = generated_text.strip()\n",
    "\n",
    "# \"Note:\"가 있다면, 그 뒤의 모든 텍스트를 제거\n",
    "if \"Note:\" in summary_only:\n",
    "    summary_only = summary_only.split(\"Note:\")[0].strip()\n",
    "\n",
    "\n",
    "# .txt 파일로 저장 \n",
    "with open(\"generated_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_only)\n",
    "\n",
    "print(\"Summary Only:\", summary_only)\n",
    "\n",
    "with open(\"generated_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_only)\n",
    "print(\"File 'generated_summary.txt' has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
